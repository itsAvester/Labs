---
title: "Lab1"
author: "Eric Vance"
format: pdf
editor: visual
date: 2025-02-02
---

## Lab1: Comparing Classification Methods

**Due: 11:59PM Friday, February 7 on Canvas as a knitted pdf file of your team's Quarto document**

1.  You will individually fit five classification models and compare their sensitivities and specificities.
2.  You will interpret these models and make a prediction in your individual section.
3.  As a team, you will create one visualization that summarizes the performance of the models.

### Instructions for Lab1

In Lab0, the professor created a generating model for Y variables taking on 0 or 1 values based on the X1 and X2 inputs. You came up with the backstory for what Y, X1, and X2 were and why it was important to use X1 and X2 to predict Y.

In this lab, you will apply four newly learned statistical learning methods to continue your analyses for how to best predict or explain Y from X1 and X2. You should continue to use the Q1 qualitative context you developed in Lab0 (or you can develop a new one if you want).

Each individual will fit five classification models on a training dataset and then evaluate how well those models classify Y based on a test dataset. Individuals will make a prediction given (x1, x2) and then interpret their prediction and make a recommendation for action. Just as in Lab0, each individual will describe the Q1, Q2, and Q3 for this "project". Specifically, for Q1: What is Y, X1, and X2, and why should we care?. Train your five models on the training set, compare the sensitivity and specificity of the models on the test set, make a prediction given (x1, x2) (this is Q2). Then describe what actions (Q3) you recommend given your Q1 context and your Q2 results. Reflect on some ethical aspect of this project.

#### Generating Model

We have a logistic regression generating model. Given $x_1 \in [0,1]$ and $x_2 \in [0,1], Y \sim Ber(p)$, where $p$ is related to $x_1$ and $x_2$ through the logistic link function: $\log(\frac{p}{(1-p)}) = x_1 -2x_2 -2{x_1}^{2} + {x_2}^{2} + 3{x_1}{x_2} +4{x_1}{x_2}^2 -3{x_1}^{2}x_2$, where $\log$ is the natural log, sometimes written as $\ln$.

The code for this is below.

```{r}
library(class)
suppressPackageStartupMessages(library(tidyverse))
```

```{r}
#Generative model
set.seed(200) #setting a random seed so that we can
#reproduce everything exactly if we want to

generate_y <- function(x1,x2) { #two input parameters to generate the output y
  logit <- x1 -2*x2 -2*x1^2 + x2^2 + 3*x1*x2 +4*x1*x2^2 -3*x1^2*x2
  p <- exp(logit)/(1+exp(logit)) #apply the inverse logit function
  y <- rbinom(1,1,p) #y becomes a 0 (with prob 1-p) or a 1 with probability p
}
```

#### Training dataset

We are going to use our generating model to create a training dataset of 1000 predictors (x1, x2), and then 1000 outcomes. Then we plot all three variables to see what our training data looks like.

```{r}
# Generate a training dataset with 1000 points
set.seed(200)
n = 1000
X1 <- runif(n,0,1)
X2 <- runif(n,0,1)

#I'm going to use a for loop to generate 1000 y's
Y <- rep(0,n) #initializing my Y to be a vector of 0's
for (i in 1:n) {
  Y[i] <- generate_y(X1[i],X2[i])
}

sum(Y) #How many 0's and 1's were predicted? In this
#training set, almost 53% were 1's. When n is very large
# about 51.5% of the Y's are 1's. That's really close to
# 50/50 so we shouldn't have issues with "imbalance"
# which is something we'll learn about later in the 
# semester.

training <- cbind(X1,X2,Y) #combining all of my variables into a training dataset
ggplot(data=training, aes(x=X1, y=X2, color=Y)) +
  geom_point()
```

How well will various classifiers predict Y given new x1 and x2 values?

#### Test datasets

Each individual will generate a test set of 1000 predictors (x1, x2) and outcomes (y) that we will use as our "ground truth".

So, create your individual test dataset (using random seed=201, 202, 203, or 204; each teammate has a different test dataset).

```{r}
# Create the training dataset as above using seed=200
# Create a testing dataset using seed=201, 202, 203, or 204

set.seed(201)
n = 1000

```

#### What individuals need to do

1.  Given the training set (seed=200), fit:
    1.  logistic regression model
    2.  linear discriminant analysis (LDA)
    3.  quadratic discriminant analysis (QDA)
    4.  naive Bayes
    5.  KNN with k=optimal k from Lab0
2.  Calculate the sensitivity, specificity, and overall error rate (misclassification rate) for each model given your test set (your seed=201 or 202 or 203 or 204).
3.  Make a prediction for a new point (x1, x2) = (0.25, 0.25) or (0.25, 0.75) or (0.75, 0.25) or (0.75, 0.75) for each fitted model. Each individual will have a different point for their predictions.
4.  Summarize the Q1, Q2, and Q3 aspects of this "project."

#### What teams need to do

1.  Summarize the models' performance using all of the results from each individual.
2.  Which is the best model to use in this situation?

#### **Some intended outcomes from this assignment:**

-   You will individually get practice fitting a logistic regression, LDA, QDA, naive Bayes, and KNN
-   You will compare the performance of these five models
-   You will make predictions based on statistical learning models
-   You will practice describing how the Q1 context affects your Q2 and Q3 outcomes, i.e., you will practice thinking about the whole problem (i.e., Q1Q2Q3, not just the Q2 quantitative parts)
-   You will compare models visually
-   You will gain experience collaborating with your teammates on an applied problem
